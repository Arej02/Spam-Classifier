import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pylab as plt


df=pd.read_csv('spam.csv',encoding="latin-1")


df1=df.copy()


df1.shape


df1.sample(5)


df1.info()





df1.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True,axis=1)


df1=df1.rename(columns={'v1':'Type','v2':'Text'})


from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()


df1.Type=le.fit_transform(df1.Type)


df1.sample(5)


df1.isnull().sum()


def delete_duplicate_values(df):
    print('Deleting the duplicated values:')
    num=df.duplicated().sum()
    if num>0:
        print(f'There are {num} duplicate values in your dataset.')
        df.drop_duplicates(keep='first',inplace=True)
        print(f'{num} duplicate values have been deleted.')
    else:
        print('There are no duplicate values.')


delete_duplicate_values(df1)


df1.Type.value_counts()


plt.pie(df1.Type.value_counts(),autopct='%0.2f',labels=['ham','spam'])
plt.title('Pie Chart of Type of text messages')
plt.show()








import nltk


#Finding the number of characters in the document:
df1['num_characters'] = df1['Text'].apply(len)


#nltk.download('punkt')
#nltk.download('punkt_tab')
df1['num_words']=df1.Text.apply(lambda x:len(nltk.word_tokenize(x)))


df1['num_sentences']=df1.Text.apply(lambda x:len(nltk.sent_tokenize(x)))


df1.sample(5)


df1[['num_characters','num_words','num_sentences']].describe().T





pd.set_option('display.max_colwidth', None)


df1[df1.num_words==220]





df1.drop(index=1578,inplace=True)


df1[['num_characters','num_words','num_sentences']].describe().T


df1[df1.num_words==196]





df1[df1.Type==0][['num_characters','num_words','num_sentences']].describe().T


df1[df1.Type==1][['num_characters','num_words','num_sentences']].describe().T





sns.histplot(df1[df1.Type==0]['num_characters'],color='green',kde=True,label='Not Spam')
sns.histplot(df1[df1.Type==1]['num_characters'],color='red',kde=True,label='Spam')
plt.legend(title='Message Type')
plt.title('Distribution of Number of Characters for Spam vs. Non-Spam Messages')
plt.show()


ham_skewness=df1[df1.Type==0]['num_characters'].skew()
spam_skewness=df1[df1.Type==1]['num_characters'].skew()


print(f' The skewness of characters in not spam messages is: {ham_skewness}')
print(f' The skewness of characters in spam messages is: {spam_skewness}')


sns.histplot(df1[df1.Type==0]['num_words'],color='purple',kde=True,label='Not Spam')
sns.histplot(df1[df1.Type==1]['num_words'],color='blue',kde=True,label='Spam')
plt.legend(title='Message Type')
plt.title('Distribution of Number of Words for Spam vs. Non-Spam Messages')
plt.show()


ham_skewness=df1[df1.Type==0]['num_words'].skew()
spam_skewness=df1[df1.Type==1]['num_words'].skew()


print(f' The skewness of words in not spam messages is:{ham_skewness}')
print(f' The skewness of words in spam messages is: {spam_skewness}')


sns.histplot(df1[df1.Type==0]['num_sentences'],color='yellow',kde=True,label='Not Spam')
sns.histplot(df1[df1.Type==1]['num_sentences'],color='black',kde=True,label='Spam')
plt.legend(title='Message Type')
plt.title('Distribution of Number of Sentences for Spam vs. Non-Spam Messages')
plt.show()


ham_skewness=df1[df1.Type==0]['num_sentences'].skew()
spam_skewness=df1[df1.Type==1]['num_sentences'].skew()


print(f' The skewness of sentences in not spam messages is: {ham_skewness}')
print(f' The skewness of sentences in spam messages is: {spam_skewness}')



